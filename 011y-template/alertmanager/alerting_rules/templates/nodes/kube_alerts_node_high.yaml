apiVersion: operator.victoriametrics.com/v1beta1
kind: VMRule
metadata:
  name: kube-node-high-rules
  namespace: monitoring
spec:
  groups:
  - name: kube-node-high-rules
    rules:
    - alert: HostOutOfMemory 
      expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
      for: 5m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
      annotations:
        summary: Host out of memory (instance {{`{{ $labels.instance }}`}})
        description: "Node memory is filling up (< 10% left)\n  VALUE = {{`{{ $value }}`}}\n  LABELS = {{`{{ $labels }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
    - alert: HostMemoryUnderMemoryPressure 
      expr: rate(node_vmstat_pgmajfault[1m]) > 500
      for: 2m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
      annotations:
        summary: Host memory under memory pressure (instance {{`{{ $labels.instance }}`}})
        description: "The node is under heavy memory pressure. High rate of major page faults\n  VALUE = {{`{{ $value }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
    - alert: HostUnusualNetworkThroughputIn 
      expr: sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 300
      for: 5m
      labels:
        severity: warning
        channel: slack
        team: devops 
        alert: kubernetes
      annotations:
        summary: Host unusual network throughput in (instance {{`{{ $labels.instance }}`}})
        description: "Host network interfaces are probably receiving too much data (> 50 MB/s)\n  VALUE = {{`{{ $value }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
    - alert: HostUnusualNetworkThroughputOut 
      expr: sum by (instance) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 300
      for: 5m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
      annotations:
        summary: Host unusual network throughput out (instance {{`{{ $labels.instance }}`}})
        description: "Host network interfaces are probably sending too much data (> 100 MB/s)\n  VALUE = {{`{{ $value }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
    - alert: HostUnusualDiskReadRate 
      expr: sum by (instance) (rate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 300
      for: 10m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
      annotations:
        summary: Host unusual disk read rate (instance {{`{{ $labels.instance }}`}})
        description: "Disk is probably reading too much data (> 100 MB/s)\n  VALUE = {{`{{ $value }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
    - alert: HostUnusualDiskWriteRate 
      expr: sum by (instance) (rate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 200
      for: 10m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
      annotations:
        summary: Host unusual disk write rate (instance {{`{{ $labels.instance }}`}})
        description: "Disk is probably writing too much data (> 100 MB/s)\n  VALUE = {{`{{ $value }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
    - alert: HostUnusualDiskReadLatency 
      expr: rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.5 and rate(node_disk_reads_completed_total[1m]) > 0
      for: 2m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
      annotations:
        summary: Host unusual disk read latency (instance {{`{{ $labels.instance }}`}})
        description: "Disk latency is growing (read operations > 500ms)\n  VALUE = {{`{{ $value }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
    - alert: HostUnusualDiskWriteLatency 
      expr: rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 0.5 and rate(node_disk_writes_completed_total[1m]) > 0
      for: 2m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
      annotations:
        summary: Host unusual disk write latency (instance {{`{{ $labels.instance }}`}})
        description: "Disk latency is growing (write operations > 500ms)\n  VALUE = {{`{{ $value }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
    - alert:  HostHighCpuLoad 
      expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
      for: 5m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
      annotations:
        summary: Host high CPU load (instance {{`{{ $labels.instance }}`}})
        description: "CPU load is > 95%\n  VALUE = {{`{{ $value }}`}}\n  LABELS = {{`{{ $labels }}`}}"
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
        dashboard_url: https://grafana.k8s.opstree.dev/explore
    - alert: HostSwapIsFillingUp 
      expr: (1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 70
      for: 2m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
      annotations:
        summary: Host swap is filling up (instance {{`{{ $labels.instance }}`}})
        description: "Swap is filling up (>80%)\n  VALUE = {{`{{ $value }}`}}\n  LABELS = {{`{{ $labels }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
    - alert: KubePersistentVolumeFillingUp 
      annotations:
        description: The PersistentVolume claimed by {{`{{ $labels.persistentvolumeclaim }}`}} in Namespace {{`{{ $labels.namespace }}`}} is only {{`{{ $value | humanizePercentage }}`}} free.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefillingup
        summary: PersistentVolume is filling up.
        dashboard_url: https://grafana.k8s.opstree.dev/explore
      expr: |-
        kubelet_volume_stats_available_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
          /
        kubelet_volume_stats_capacity_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
          < 0.03
      for: 1m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
    - alert: KubePersistentVolumeErrors 
      annotations:
        description: The persistent volume {{`{{ $labels.persistentvolume }}`}} has status {{`{{ $labels.phase }}`}}.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeerrors
        summary: PersistentVolume is having issues with provisioning.
        dashboard_url: https://grafana.k8s.opstree.dev/explore
      expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
      for: 1m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
    - alert: NodeNetworkInterfaceFlapping 
      annotations:
        message: Network interface "{{`{{ $labels.device }}`}}" changing it's up status often on node-exporter {{`{{ $labels.namespace }}`}}/{{`{{ $labels.pod }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        summary: "Network Interface Flapping Detected"
        description: "This alert triggers when a network interface on a node exhibits frequent changes in its operational state, indicating potential instability or configuration issues."
      expr: changes(node_network_up{job="node-exporter",device!~"veth.+"}[2m]) > 2
      for: 2m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
 
    - alert: NodeFilesystemSpaceFillingUp 
      annotations:
        description: Filesystem on {{`{{ $labels.device }}`}} at {{`{{ $labels.instance }}`}} has only {{`{{ printf "%.2f" $value }}`}}% available space left and is filling up fast.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemspacefillingup
        summary: Filesystem is predicted to run out of space within the next 4 hours.
        dashboard_url: https://grafana.k8s.opstree.dev/explore
      expr: |-
        (
          node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100 < 15
        and
          predict_linear(node_filesystem_avail_bytes{job="node-exporter",fstype!=""}[6h], 4*60*60) < 0
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes

    - alert: NodeFilesystemFilesFillingUp 
      annotations:
        description: Filesystem on {{`{{ $labels.device }}`}} at {{`{{ $labels.instance }}`}} has only {{`{{ printf "%.2f" $value }}`}}% available inodes left and is filling up fast.
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodefilesystemfilesfillingup
        summary: Filesystem is predicted to run out of inodes within the next 4 hours.
      expr: |-
        (
          node_filesystem_files_free{job="node-exporter",fstype!=""} / node_filesystem_files{job="node-exporter",fstype!=""} * 100 < 20
        and
          predict_linear(node_filesystem_files_free{job="node-exporter",fstype!=""}[6h], 4*60*60) < 0
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
    - alert: NodeNetworkReceiveErrs 
      annotations:
        description: '{{`{{ $labels.instance }}`}} interface {{`{{ $labels.device }}`}} has encountered {{`{{ printf "%.0f" $value }}`}} receive errors in the last two minutes.'
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodenetworkreceiveerrs
        summary: Network interface is reporting many receive errors.
        dashboard_url: https://grafana.k8s.opstree.dev/explore
      expr: rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01
      for: 1h
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes
    - alert: NodeNetworkTransmitErrs 
      annotations:
        description: '{{`{{ $labels.instance }}`}} interface {{`{{ $labels.device }}`}} has encountered {{`{{ printf "%.0f" $value }}`}} transmit errors in the last two minutes.'
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-nodenetworktransmiterrs
        summary: Network interface is reporting many transmit errors.
        dashboard_url: https://grafana.k8s.opstree.dev/explore
      expr: rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m]) > 0.01
      for: 1h
      labels:
        severity: warning
        channel: slack
        team: devops
    - alert: HostOomKillDetected 
      expr: increase(node_vmstat_oom_kill[1m]) > 5
      for: 0m
      labels:
        severity: warning
        channel: slack
        team: devops
        alert: kubernetes        
      annotations:
        summary: Host OOM kill detected (instance {{`{{ $labels.instance }}`}}) 2 times in last 1 minute
        description: "OOM kill detected\n  VALUE = {{`{{ $value }}`}}\n  LABELS = {{`{{ $labels }}`}}"
        dashboard_url: https://grafana.k8s.opstree.dev/explore
        runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md
